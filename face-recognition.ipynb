{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_facenet import FaceNet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_path = 'people/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anchors = os.listdir(anchor_path)\n",
    "embeddings = []\n",
    "names = []\n",
    "for image_name in anchors:\n",
    "    image = plt.imread(anchor_path + image_name)\n",
    "    faces = embedder.extract(image, threshold = 0.96)\n",
    "#     print(faces[0].keys())\n",
    "#     x1, y1, w, h = faces[0]['box']\n",
    "#     x2, y2, = x1 + w, y1 + h\n",
    "    try:\n",
    "#         cropped_image = image[y1:y2, x1:x2]\n",
    "#         plt.imshow(cropped_image)\n",
    "#         plt.show()\n",
    "        embeddings.append(np.squeeze(faces[0]['embedding']))\n",
    "        names.append(image_name.split('.')[0])\n",
    "    except:\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names_df = pd.DataFrame(names, columns = ['Name'])\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "final_df = pd.concat([names_df,embeddings_df], axis = 1)\n",
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Encodings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Encodings_df = pd.read_csv('Encodings.csv')\n",
    "Encodings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare(v1):\n",
    "    min_distance = 1000000.0\n",
    "    final_name = ''\n",
    "    for i in range(len(Encodings_df)):\n",
    "        row = Encodings_df.iloc[i,]\n",
    "        name = row['Name']\n",
    "        v2 = row[Encodings_df.columns[1:]]\n",
    "        dist = np.linalg.norm(v1-v2)\n",
    "        if dist < min_distance:\n",
    "            min_distance = dist\n",
    "            final_name = name\n",
    "    return final_name\n",
    "\n",
    "    \n",
    "def identify(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    names = []\n",
    "    faces = embedder.extract(image, threshold = 0.97)\n",
    "    for face in faces:\n",
    "        if face['confidence'] >= 0.97:\n",
    "            x1, y1, w, h = face['box']\n",
    "            x2, y2 = x1+w, y1+h\n",
    "            plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1])\n",
    "            encoding = face['embedding']\n",
    "            name = compare(encoding)\n",
    "            plt.text(x1,y1, name, bbox = dict(fill = True, linewidth = 1))\n",
    "            names.append(name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return names\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to take picture from webcam and recognise Face\n",
    "import cv2, time\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "time.sleep(1)\n",
    "check, image = camera.read()\n",
    "time.sleep(1)\n",
    "if check:\n",
    "    names = identify(image)\n",
    "camera.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'test/'\n",
    "for name in os.listdir(test_path):\n",
    "    image = plt.imread(test_path + name)\n",
    "    names = identify(image)\n",
    "#     print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "x = Encodings_df.iloc[:,np.arange(1,511)].values\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = pca.fit_transform(x)\n",
    "principal_df = pd.DataFrame(principal_components, columns = ['component_1', 'component_2'])\n",
    "principal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = principal_df['component_1']\n",
    "ys = principal_df['component_2']\n",
    "\n",
    "names = Encodings_df['Name']\n",
    "colors = np.arange(0,len(xs))\n",
    "for i in range(len(xs)):\n",
    "    plt.scatter([xs[i]], [ys[i]], label = names[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('env': venv)",
   "language": "python",
   "name": "python38264bitenvvenv5f400ae4f1ae43adb34e34dd19870237"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
